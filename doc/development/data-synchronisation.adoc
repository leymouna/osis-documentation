= Synchronisation de donnée entre EPC et OSIS
Philippe Bruyère, Benoît Moreau, Hang Hoang, Hildeberto Mendonça
v0.1, 2015-10-29
:toc: right

== Données

=== EPC

==== Databases

There are 5 EPC databases, one for each EPC instance - *dev*, *test*, *qa*, *demo* and *production*. Within each database, EPC has access to 8 schemes - *epc*, *aid*, *fgs*, *mnd*, *pres*, *std*, *str* and *doctorats*. The schema epc depends on fgs, mnd, pres, std and str. The schema aid depends on epc. The schema doctorats is isolated. These schemes are in the scope of the database migration.

==== Files

For performance reasons, files generated by EPC are stored in a network storage space. Only references for those files are kept in the database. It significantly improved performance and maintenance in comparison to storing files directly in the database, as it was done before. Documents have an expiration date which varies from 0, for temporary files, to 3 years for more relevant documents. Since no document is older than three years, historical data are not an issue.

=== OSIS

=== Data Migration

Once the decision to migrate the applications to Odoo was made, a detailed technical analysis takes place to identify the implications of this migration in order to help decision makers to define priorities and conceive a realistic planning. The current assumption is that the data is probably the only resource that will be preserved in the process of rewriting all applications on Odoo's framework. Therefore, this document focus on the data migration only.

Odoo completely abstracts the database from programmers. The database model is created using a object-relational model where classes are used to represent database tables. Objects from those classes represent data from their respective tables. The difference from the current architecture is that programmers are fully responsible for creating the physical model while Odoo takes full responsibility over this model. Therefore, there is a very low probability that the current data model is anyhow compatible with data models managed by Odoo.

A clear evidence of that is the approach adopted by Odoo to define primary keys. While it always define a unique, numeric, auto-incremented identifier, the current physical model uses all sorts of approaches such as: single numeric column, single character column, multiple numeric columns, multiple heterogeneous columns and others. Therefore, preserving the referential integrity of the data is probably the most challenging issue to be addressed in this analysis.
This document aims to support the decision making of the project manager by gathering technical information about the data, analyzing the implications and proposing solutions for the identified issues.

==== Strategies

The main issue identified in the previous section is how to preserve referential integrity when the data is spread in different database servers. We will probably never find a 100% reliable solution given the complexity of distributed systems, but we can considerably reduce the risk of data inconsistencies by carefully evaluating all possible alternatives and picking the one with the best cost-benefit. This is indeed an effort that cannot be postponed neither avoided. We have figured 5 migration strategies, as described hereafter.

===== Synchronize data using a synchronization tool

A off-the-shelf product is used to synchronize data between Oracle and PostgreSQL bidirectionally. This solution considers that the data model is identical or very similar in both databases. This strategy is very unlikely because EPC's data model do not follow standard rules, while Odoo follows strict rules enforced by its persistence mechanism. These discrepancies may force the implementation of very specific migration logic, which is not usually covered by migration tools.

image::images/ots-sync-tool.png[]

===== Write a program to migrate data from Oracle to PostgreSQL

It seems to be inevitable the development of a custom migration tool to address this particular data migration scenario. Therefore, all the following strategies consider some level of additional development. This one, in particular, considers the development of a tool that is scheduled to run periodically, calculating the delta between both databases and updating the most out dated one.

image::images/st-sync-tool.png[]

The data model can be different because the tool encapsulates all data transformations between the models. The data model can evolve and solve current issues.

It might be more complex and more time consuming and, since it does not use the business layer to process the data, it can become inconsistent over time if the tool does not follow carefully all changes in the business layer (i.e. boundaries of transactional business operations on multiple tables can guarantee consistency while unbounded transactions made by a synchronization tool may fail, causing inconsistency).

===== Change both applications to access each other's web services

This strategy address the disadvantages of the previous one by forcing the use of the business layer during the data migration. It is possible because all updates are done through web services that processes the data in the business layer before persisting then in the database.

image::images/wsc-sync-tool.png[]

The disadvantage is that it makes EPC and Odoo highly coupled because it forces both applications to be aware of each other. As a consequence, a locoincide comt of code would have to be removed from Odoo after the complete phase out of EPC. This is a hard task because we it is not easy to distinguish which code is concrete and which one is volatile.

===== Change one of the applications to access other's web services

We could reduce high coupling by concentrating all changes for data migration on the EPC side. This way, the migration code would be discarded with EPC, leaving Odoo free of volatile code. EPC would call Odoo's web services to update its own data for every table owned by Odoo. These  data would be available read-only on EPC.

image::images/wsc-st-sync-tool.png[]

Unfortunately, an additional tool would be necessary to keep Odoo up to date with data from those tables that are still owned by EPC.

===== Post on a queue every time an update in the database occurs

This is probability the strongest strategy because it addresses all previous drawbacks. Every update on tables not yet owned by Odoo would cause a post of a message in a queue. Messages in this queue would be read by a tool, which would call Odoo web services to pass through the business layer before updating the database.

It is feasible because the business layer in EPC is implemented using EJBs and an interceptor can be attached to a EJB to have access to the data passed as arguments and returned to the caller. An interceptor would be responsible for posting on the queue.  This way, every update done by EPC is immediately available on Odoo's data model on demand.

image::images/queue-sync-tool.png[]

To identify potential drawbacks, it would be necessary to implement a proof-of-concept in order to address unforeseen issues before starting the migration to Odoo.

=== Historical Data

The current database stores data since 1984, which matches with the beginning of information systems adoption. These data are preserved, but most of them are not useful anymore for current operational processes. They actually contribute to slow down the application by constantly increasing the size of the indexes.

Historical data cannot be simply ignored in a completely new application because the nature of EPC's data is historical by default. For example, data related to students should be available from the oldest active student until the newest one, making the studies history always available for regular reporting and updates. The period in which historical data are useful might be large, but more than 30 years of historical data certainly exceeds any reasonable limit.

The challenge is to differentiate useful historical data from archivable ones. We start by classifying EPC data in four categories:

1. *Master data*:  related to the core business but treated individually, outside of a process context. For example: offers, activities, courses, etc.

2. *Business process data*: related to business processes, such as deliberation, registrations, activities approval, encodage des notes, etc.

3. *Reference data*: not directly related to the business, but related to the education domain, complementing master data. For example: countries, languages, postal codes, etc.

4. *Auditing data*: every time a record changes a version of it is preserved in an auditing table for possible data recovery.

The data within those categories can be:

1. *Operational*: data frequently updated and retrieved from the database for on-line use or reporting. All categories above contains operational data.

2. *Archivable*: data that are not used anymore in the current business context, unless for some historical reports. Business process and auditing data are strong candidates for archiving. Master and reference data are usually required for a longer period of time and should be analyzed case by case.

=== Signalétique student etd_signaletique

Remarques:

J'écarte donc les champs qui ne servent pas par défaut au business de l'encodage des notes.

Dans EPC, on peut chercher par le phonème, ou par le nom_tri/prénom_tri
je suppose que odoo fait mieux et que ces champs techniques ne sont pas nécessaires

Je sélectionne les étudiants qui ont pu faire l'objet d'une inscription valable à l'année académique.

J'écarte donc les étudiants en demande ou en erreur mais je reprends les décès.

Je sélectionne des champs connexes à l'identification, qui pourraient servir à identifier précisément une personne ou servir à la contacter.

Peut-être faut-il décoder les données potentiellement énumérées, à confirmer:

(On sélectionne uniquement les etd_signaletique qui ont un fgs_fgs associé)

    select t1.noma, t1.nom, t1.prenom1, t1.date_naissance,
        t1.prenoms_suivants, t1.annee_naissance, t1.lieu_naissance,
        t1.pays_naissance, t1.sexe, t1.etat_civil, t1.num_social,
        t1.gsm, t1.email
    from etd_signaletique t1
        join etd_sign_anac t2 on t2.noma = t1.noma
        join fgs_four on matric_four = t1.noma and fichier = 2
    where t2.anac = 2015
        and t2.etat_role in ('1','3','4','5','6','7','8');

=== res.partner fgs_fgs

Je reprends tous les membres du personnel actifs, et les étudiants au moins une fois inscrits en 2015 qui ont reçu un matricule FGS:

    select fgs_fgs.matric_fgs, fgs_fgs.nom, fgs_fgs.prenom,
           fgs_fgs.dte_nais, fgs_fgs.leg_rue, fgs_fgs.leg_copo,
           fgs_fgs.leg_comm, std_nation.iso
    from fgs.fgs_fgs join fgs.fgs_four
                     on fgs_four.matric_fgs = fgs_fgs.matric_fgs
                     left join std.std_nation
                     on std_nation.code_cref = fgs_fgs.leg_cpays
    where fgs_four.fichier = 1
          and fgs_four.type in (1,2)
          union select fgs_fgs.matric_fgs, fgs_fgs.nom,
                       fgs_fgs.prenom, fgs_fgs.dte_nais,
                       fgs_fgs.leg_rue, fgs_fgs.leg_copo,
                       fgs_fgs.leg_comm, std_nation.iso
                from fgs.fgs_fgs join fgs.fgs_four
                     on fgs_four.matric_fgs = fgs_fgs.matric_fgs
                     join epc.etd_sign_anac
                     on etd_sign_anac.noma = fgs_four.matric_four
                     left join std.std_nation
                     on std_nation.code_cref = fgs_fgs.leg_cpays
                where fgs_four.fichier = 2
                      and etd_sign_anac.anac = 2015;

=== offer epc_offre_sigle_suivi, epc_offre_sigle, epc_offre_uclouvain, epc_offre
  !!!!! Il faut absolument revoir comment on restructure des tables, des champs qui concernent l'Offre dans OSIS. On ne peut pas garder la même structure.

    select offre_sigle_suivi_id, descrption
    from epc_offre_sigle_suivi;

    select offre_sigle_id, sigle, ocycle, niveau, lettres_finales,
           orientation, offre_sigle_suivi_id
    from epc_offre_sigle;

Attention! 12 étudiants encore inscrits à des années de validité d'offre < 2015 en 2015.
Il s'agit 1 offre "ALGO2FC" et une inscription par erreur à MD11BA. On va demander à l'utilisateur de changer.
On n'injecte pas des offres avant 2015 pour l'encodage de notes cette année.


    select offre_uclouvain_id, validite, offre_sigle_id,
           intit_complet, intit_abrege, intit_orientation,
           intit_diplome, duree, typduree, nbr_epreuve, diplome,
           inscriptible
    from epc_offre_uclouvain
    where validite = 2015;

Je pensais ne reprendre que sigle_gestion. 90% des secsigle sont identiques à sigle_gestion donc voir si pertinent.

Les cours dont le sigle de gestion est une commission doctorale ont le secteur comme sigle d'administration; étudier l'impact pour le vrai odoo.

À partir du moment où "on" souhaite distinguer les sessions dans les inscriptions aux examens, il me semblerait cohérent d'en faire autant pour les champs relatifs aux sessions dans epc_offre; à vous de voir.

    select num_offre, sigle_gestion, secsigle, validite,
           offre_uclouvain_id, date_note1, date_note2, date_note3,
           heure_note1, heure_note2, heure_note3
    from epc_offre where validite = 2015;

=== structure str.str_entite.

Je considère que l'identifiant non unique num_entite n'est pas pertinent; seul le sigle identifie dans la période relative à l'année académique.

Si l'adresse de l'entité est nécessaire, je devrai ajouter les champs de la table str.str_adresse mais les intégrer dans la structure, pas besoin d'une table dépendante.

    select sigle, sigle_dpt, sigle_fac, sigle_eco, sigle_secteur,
           denomination, debut_validite, fin_validite
    from str.str_entite
    where debut_validite <= '01/09/2015'
          and fin_validite >= '31/12/2015'

    On ne prend que les entités qui sont actifs en 2015 pour l'encodage de notes

=== learning_unit epc.epc_ele

    select distinct num_ele, debut_ens, fin_ens
    from epc_ele
    where validite = 2015 and type_ele > 0;

=== learning_unit_year

Je reprends les activités 2015, les groupements sont d'office écartés. Faut-il reprendre les poids absolus, les volumes, les infos sur les quadrimestres? Peut-être faut-il écarter les cours en proposition de création.

Attention! Il y a des inscriptions aux cours 2009 à 2016! en 2015: On ne doit pas tenir compte de ces cours, car il s'agit des reports ou des dispenses

    select num_ele, validite, sigle_ele, cnum, subdivision,
           intit_abrege, intit_complet, dpt_charge, dpt_attrib,
           type_ele
    from epc_ele
    where validite = 2015 and type_ele > 0;

=== attribution epc.epc_ele_itv

Les candidatures et les causes de vacances sont éliminées.

Attention! les attributions à somebody sont conservées.

    select num_ele_itv, num_ele, matric_itv, debut_attr, duree_attr,
           fonct_moyen
    from epc_ele_itv, fgs_fgs
    where validite = 2015 and candidature = 0
          and matric_itv = matric_fgs and cause_vac = '0';

=== learning_unit_enrollment  epc.etd_insc_cours

Remarque: il y a déjà des notes reportées ou autres raisons en janvier.

J'ai repris le numéro d'enregistrement des notes, seul Benoit et Evase savent si c'est encore utilisé.

J'ai indiqué un champ session fictif juste pour mémoire, à vous de voir comment vous gérez cela.

    select noma, num_ele, anac, anac_ref_ele, section, etat_cours
    from etd_insc_cours
    where anac = 2015;

=== exam_enrollment epc.etd_insc_cours

Remarque: il y a déjà des notes reportées ou autres raisons en janvier.

J'ai repris le numéro d'enregistrement des notes, seul Benoit et Evase savent si c'est encore utilisé.

J'ai indiqué un champ session fictif juste pour mémoire, à vous de voir comment vous gérez cela.

    select noma, num_ele, anac, anac_ref_ele, section,
          1 as "SESSION", etat_exam_1, note_1, apprec_1,
          mention_1, credit_1, num_enr_note_1
    from etd_insc_cours
    where anac = 2015;

Il y a actuellement 7.721.689 records dans etd_insc_cours; et 13.000.000 d'inscriptions aux examens. On va donc vers un système de 20.0000.0000 de records. Je ne conteste pas le nouveau modèle pour remplacer etd_insc_cours, mais il faut le savoir pour anticiper les questions de performances.
